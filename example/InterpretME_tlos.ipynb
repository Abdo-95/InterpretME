{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16d2e2c5",
   "metadata": {},
   "source": [
    "# Interpretable ML over an Extended Version of  the French Royalty KG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e8317",
   "metadata": {},
   "source": [
    "This an example on how **InterpretME** can be used to interpret the prediction and trace back a particular target entity. The KG of the *French Royalty Benchmark* is a fully curated subset of DBpedia; for each person we added the class `dbo:Person` as well as different properties like the number of children or predecessors, and further triple related counts. Here, the predictive task is a binary classification to predict whether a person has a spouse. The statistics of the *French Royalty KG* are presented in the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5774cfe1",
   "metadata": {},
   "source": [
    "| #triples | #entities | #predicates | #objects | #triples / #entities |\n",
    "| :-: | :-: | :-: | :-: | :-: |\n",
    "| 31,599 | 3,439 | 133 | 4,390 | 9.18 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b60a372",
   "metadata": {},
   "source": [
    "## Let's Start with Essentials for this Tutorial Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1938629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install /Users/a.arnous/workspace/InterpretME\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e8c33a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Note:</b> You may need to restart the kernel to use the updated packages!</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d0d1777",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851cffd5",
   "metadata": {},
   "source": [
    "The mechanism of InterpretME is as follows:<br>\n",
    "<ol>\n",
    "  <li>SHACL validation</li>\n",
    "  <li>Data preprocessing</li>\n",
    "  <li>Training of the predictive model</li>\n",
    "  <li>Understanding the results of interpretability models (e.g., LIME)</li>\n",
    "  <li>Semantify collected metadata</li>\n",
    "  <li>Uploading semantified metadata into Virtuoso</li>\n",
    "  <li>Querying the InterpretME KG and input KG to trace back all properties of a particular entity</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47ef681",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Note:</b> If you don't have Docker (and docker-compose) installed. Please, follow the instructions according to configuration of your machine.\n",
    "\n",
    "<ul>\n",
    "        <li><b>Linux:</b> <a href=\"https://docs.docker.com/desktop/install/linux-install/\" target=\"_blank\">https://docs.docker.com/desktop/install/linux-install/</a></li>\n",
    "        <li><b>Windows:</b> <a href=\"https://docs.docker.com/docker-for-windows/install/\" target=\"_blank\">https://docs.docker.com/docker-for-windows/install/</a></li>\n",
    "        <li><b>Mac:</b> <a href=\"https://docs.docker.com/docker-for-mac/install/\" target=\"_blank\">https://docs.docker.com/docker-for-mac/install/</a></li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4f1a31",
   "metadata": {},
   "source": [
    "To get started with the **KG**, you need to start the containers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4adcc31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpretmekg is up-to-date\n",
      "frenchroyalty is up-to-date\n",
      "interpretme is up-to-date\n"
     ]
    }
   ],
   "source": [
    "!docker-compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33924b",
   "metadata": {},
   "source": [
    "Importing required modules from **InterpretME** library:\n",
    "\n",
    "* `pipeline()`: Run the predictive tasks and interpretation tools (e.g., LIME).\n",
    "* `plots.sampling()`: Generates plot of the target class distribution.\n",
    "* `plots.feature_importance()`: Creates bar plot of important features.\n",
    "* `plots.decision_trees()`: Generates trees of predictions made by predictive model.\n",
    "* `plots.constraints_decision_trees()`: Trees are incorporated with SHACL validation results.\n",
    "* `federated()`: Query the *InterpretME KG* and the input KG to trace back all properties of a target entity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "568d812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from InterpretME import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b438562",
   "metadata": {},
   "source": [
    "**InterpretME** takes a JSON file as input (i.e., *URL of the input KG, features’ definition, target definition, SHACL constraints, sampling strategy, class definition*); a `SPARQL query` is generated based on the feature definition given by the user and the query is used to retrieve the application domain data from the input KG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ca3c77",
   "metadata": {},
   "source": [
    "Given the input **KG** that integrates the features’ and class target definitions about French Royalty; and their SHACL constraints. The features’ definition is classified into independent and dependent variables; later used in the predictive modeling pipeline. The features can be defined in the following format:\n",
    "\n",
    "```JSON\n",
    "{\n",
    "    \"path_to_data\": \"dataset/tlos_v1.csv\",\n",
    "    \"Type\": \"Patient\",\n",
    "    \"Index_var\": \"index\",\n",
    "    \"Independent_variable\": [\"sex\", \"age\", \"an_parenchymal_opacification\", \"an_cardiac_silhouette_enlargement\", \"an_pleural_effusion\"],\n",
    "    \"Dependent_variable\": [\"event\"],\n",
    "    \"classes\": {\n",
    "      \"Dead\": \"0\",\n",
    "      \"Alive\": \"1\"\n",
    "    },\n",
    "    \"sampling_strategy\": \"undersampling\",\n",
    "    \"number_important_features\": 6,\n",
    "    \"cross_validation_folds\": 5,\n",
    "    \"test_split\": 0.3,\n",
    "    \"model\": \"Random Forest\",\n",
    "    \"min_max_depth\": 4,\n",
    "    \"max_max_depth\": 6\n",
    "  }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c92a34c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Note:</b> As of v1.2.0, InterpretME is also able to work with CSV and JSON datasets. See `example_csv_french_royalty.json` for an example configuration for datasets.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e89fd3",
   "metadata": {},
   "source": [
    "The purpose of `pipeline()` is to assemble several components of **InterpretME** that can be evaluated together while setting different parameters. First, it starts with evaluating the SHACL constraints over the nodes of input KGs and generates a validation report per target entity. This report shows if a particular entity validates/invalidate the constraints defined by the user. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79a2b0f",
   "metadata": {},
   "source": [
    "The *data preprocessing* step includes transforming the data extracted from the input KG into a form that can be used to train the predictive pipeline. To avoid imbalance, the sampling strategy defined by the user is deployed. To handle categorical values from data, one-hot encoding is utilized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3c5a5b",
   "metadata": {},
   "source": [
    "The *predictive model building* step can be achieved based on user preferences. Given the French Royalty preprocessed data, automated tools are utilized for models (e.g., *Ensemble Learning*) and to optimize the hyperparameter selection for predictive tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ff7c70",
   "metadata": {},
   "source": [
    "Here, the automated predictive model can perform stratified shuffle split cross-validation with *Random Forest*, *Adaboost Classifier*, or *Gradient Boosting Classifier* and identify the relevant features; they are used to train a *Decision Tree* classifier to predict and visualize the outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a901cc0",
   "metadata": {},
   "source": [
    "In this step, the metadata collected are the features' definition, trained model, hyperparameters, predictions, precision, recall, classification report, as well as confusion matrix files generated from the trained predictive model. The metadata are later used in the creation of InterpretME KG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5c182d",
   "metadata": {},
   "source": [
    "The current version of InterpretME uses *LIME* [1] to have local interpretations of the target entities.\n",
    "*LIME* also identifies the top-10 relevant features for the target entity and assigns weights. The results allow the user to understand the quality of the predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e1e03e",
   "metadata": {},
   "source": [
    "The RDF mapping language (RML) is used to define mappings for the metadata collected from the predictive pipeline in order to integrate them into the **InterpretME KG**.\n",
    "The RML mappings are used by the SDM-RDFizer [2], an efficient RML engine for creating knowledge graphs, to semantify the metadata. InterpretME relies on **FAIR** principles for defining the *InterpretME ontology* by extending *ML schema*; it is available on [VoCol](http://ontology.tib.eu/InterpretME/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56989a8",
   "metadata": {},
   "source": [
    "The generated RDF data will be uploaded to an instance of *Virtuoso*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0172ae9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b213b0c9be46a28225b25ad1e90c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "InterpretME Pipeline:   0%|          | 0/5 [00:00<?, ?task/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "exepected pandas.DataFrame, but got <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/a.arnous/workspace/InterpretME/example/InterpretME_tlos.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/a.arnous/workspace/InterpretME/example/InterpretME_tlos.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results \u001b[39m=\u001b[39m pipeline(path_config\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./example_cvs_tlos_v1.json\u001b[39;49m\u001b[39m'\u001b[39;49m, lime_results\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./output/lime\u001b[39;49m\u001b[39m'\u001b[39;49m, survshap_results\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./output/survshap\u001b[39;49m\u001b[39m'\u001b[39;49m, server_url\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhttp://localhost:8891/\u001b[39;49m\u001b[39m'\u001b[39;49m, username\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdba\u001b[39;49m\u001b[39m'\u001b[39;49m, password\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdba\u001b[39;49m\u001b[39m'\u001b[39;49m, survival\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/InterpretME/pipeline.py:411\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(path_config, lime_results, survshap_results, server_url, username, password, survival, sampling, cv, imp_features, test_split, model)\u001b[0m\n\u001b[1;32m    406\u001b[0m utils\u001b[39m.\u001b[39mpbar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n\u001b[1;32m    408\u001b[0m \u001b[39m###***   <MODEL BULDING & CLASSIFICATION>  ***###\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \n\u001b[1;32m    410\u001b[0m \u001b[39m# Train the machine learning model and make predictions\u001b[39;00m\n\u001b[0;32m--> 411\u001b[0m new_sampled_data, clf, results \u001b[39m=\u001b[39m classification\u001b[39m.\u001b[39;49mclassify(sampled_data, sampled_target, imp_features, cv, classes, st, survival, lime_results, survshap_results, test_split, model, results, min_max_depth, max_max_depth)\n\u001b[1;32m    412\u001b[0m processed_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat((new_sampled_data, sampled_target), axis\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    413\u001b[0m processed_df\u001b[39m.\u001b[39mreset_index(inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/InterpretME/classification.py:95\u001b[0m, in \u001b[0;36mclassify\u001b[0;34m(sampled_data, sampled_target, imp_features, cv, classes, st, survival, lime_results, survshap_results, train_test_split, model, results, min_max_depth, max_max_depth)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Selecting classification strategy based on the number of classes provided by the user.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \n\u001b[1;32m     66\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m \n\u001b[1;32m     93\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(classes) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     new_sampled_data, clf, results \u001b[39m=\u001b[39m binary_classification(sampled_data, sampled_target, imp_features, cv, classes,\n\u001b[1;32m     96\u001b[0m                                                            st, survival, lime_results, survshap_results, train_test_split, model, results, min_max_depth, max_max_depth)\n\u001b[1;32m     97\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     new_sampled_data, clf, results \u001b[39m=\u001b[39m multiclass(sampled_data, sampled_target, imp_features, cv, classes, st, survival,\n\u001b[1;32m     99\u001b[0m                                                 lime_results, survshap_results, train_test_split, model, results, min_max_depth, max_max_depth)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/InterpretME/classification.py:327\u001b[0m, in \u001b[0;36mbinary_classification\u001b[0;34m(sampled_data, sampled_target, imp_features, cross_validation, classes, st, survival, lime_results, survshap_results, test_split, model, results, min_max_depth, max_max_depth)\u001b[0m\n\u001b[1;32m    324\u001b[0m     lime_interpretation(X_train, new_sampled_data, best_clf, ind_test, X_test, classes, st, lime_results)\n\u001b[1;32m    326\u001b[0m \u001b[39melif\u001b[39;00m survival \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m: \n\u001b[0;32m--> 327\u001b[0m     survshap\u001b[39m.\u001b[39;49mSurvShap_interpretation(X_train, new_sampled_data, best_clf, X_test, st, survshap_results\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    330\u001b[0m \u001b[39m# Saving the classification report\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39mwith\u001b[39;00m stats\u001b[39m.\u001b[39mmeasure_time(\u001b[39m'\u001b[39m\u001b[39mPIPE_OUTPUT\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/validating_models/stats.py:99\u001b[0m, in \u001b[0;36mtimeit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     98\u001b[0m     \u001b[39mwith\u001b[39;00m measure_time(category):\n\u001b[0;32m---> 99\u001b[0m         res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/InterpretME/survshap.py:48\u001b[0m, in \u001b[0;36mSurvShap_interpretation\u001b[0;34m(X_train, new_sampled_data, best_clf, X_test, st, survshap_results)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39m@time_survshap\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mSurvShap_interpretation\u001b[39m(X_train, new_sampled_data, best_clf, X_test, st, survshap_results\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     24\u001b[0m \u001b[39m        \u001b[39m\u001b[39m\"\"\"Generates SurvShap interpretation results.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \n\u001b[1;32m     47\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m         y_train \u001b[39m=\u001b[39m Surv\u001b[39m.\u001b[39;49mfrom_dataframe(\u001b[39m\"\u001b[39;49m\u001b[39mevent\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m\"\u001b[39;49m, X_train)\n\u001b[1;32m     50\u001b[0m         \u001b[39m# get column names of important features and remove event and time columns\u001b[39;00m\n\u001b[1;32m     51\u001b[0m         imp_feature_cols \u001b[39m=\u001b[39m new_sampled_data\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sksurv/util.py:92\u001b[0m, in \u001b[0;36mSurv.from_dataframe\u001b[0;34m(event, time, data)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Create structured array from data frame.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \n\u001b[1;32m     77\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39m    Structured array with two fields.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, pd\u001b[39m.\u001b[39mDataFrame):\n\u001b[0;32m---> 92\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     93\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mexepected pandas.DataFrame, but got \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(data)))\n\u001b[1;32m     95\u001b[0m \u001b[39mreturn\u001b[39;00m Surv\u001b[39m.\u001b[39mfrom_arrays(\n\u001b[1;32m     96\u001b[0m     data\u001b[39m.\u001b[39mloc[:, event]\u001b[39m.\u001b[39mvalues,\n\u001b[1;32m     97\u001b[0m     data\u001b[39m.\u001b[39mloc[:, time]\u001b[39m.\u001b[39mvalues,\n\u001b[1;32m     98\u001b[0m     name_event\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(event),\n\u001b[1;32m     99\u001b[0m     name_time\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(time))\n",
      "\u001b[0;31mTypeError\u001b[0m: exepected pandas.DataFrame, but got <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "results = pipeline(path_config='./example_cvs_tlos_v1.json', lime_results='./output/lime', survshap_results='./output/survshap', server_url='http://localhost:8891/', username='dba', password='dba', survival=1)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c828f1",
   "metadata": {},
   "source": [
    "### Exploration of Predictive Results via Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eacff7",
   "metadata": {},
   "source": [
    "To understand the trained predictive model's decisions, an automated model is deployed and a visualization of the prediction is performed via *Decision Trees*. Here, the user can also visualize SHACL constraints with decision trees which shows entities violating the constraints/validating constraints. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5379fd",
   "metadata": {},
   "source": [
    "The user can provide the path where to store the output plots, like sampling strategy (target class distribution), feature importance, and decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141012df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show SVG in Jupyter notebook\n",
    "from IPython.display import SVG, display\n",
    "import os\n",
    "def show_svg(rel_path):\n",
    "    if type(rel_path) == list:\n",
    "        for path in rel_path:\n",
    "            show_svg(path)\n",
    "    else:\n",
    "        display(SVG(url='file://' + os.getcwd() + '/' + rel_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c9748d",
   "metadata": {},
   "source": [
    "#### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e132f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.sampling(results=results, path='./output/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edfb4b4",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd687f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.feature_importance(results=results, path='./output/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5004a9e6",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868676a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_svg(plots.decision_trees(results=results, path='./output/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d953304",
   "metadata": {},
   "source": [
    "#### Decision Trees with Constraint Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b626fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_svg(plots.constraints_decision_trees(results=results, path='./output/', constraint_num=[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490c2e4d",
   "metadata": {},
   "source": [
    "### Federated Query Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7620bc",
   "metadata": {},
   "source": [
    "After uploading the semantified results to the InterpretME KG, [DeTrusty](https://github.com/SDM-TIB/DeTrusty) [3] is utilized to answer the user's questions via SPARQL queries over **both** the input KG and the *InterpretME KG*. In `./queries/french_royalty` you can find templates for answering the following questions:\n",
    "1. Which is the target entity interpreted by LIME?\n",
    "2. How does ***feature*** contribute to the classification of this entity in class ***class***\n",
    "3. Which other features are relevant for this classification?\n",
    "4. Does this target entity satisfy the domain integrity constraints?\n",
    "5. What are the main characteristics of the target entity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23affc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from InterpretME.federated_query_engine import configuration, federated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a98e26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_query = \"\"\"\n",
    "SELECT DISTINCT ?sourceEntity ?InterpretableTool ?feature ?value ?targetClass ?probability\n",
    "WHERE {\n",
    "    SERVICE <http://localhost:8891/sparql> {\n",
    "        FILTER( ?LIMEentity=<http://interpretme.org/entity/Louis_XIV> )\n",
    "        ?entity a <http://interpretme.org/vocab/TargetEntity> .\n",
    "        ?entity <http://www.w3.org/2002/07/owl#sameAs> ?sourceEntity .\n",
    "        ?entity <http://interpretme.org/vocab/hasEntity> ?LIMEentity .\n",
    "        ?entity <http://interpretme.org/vocab/hasInterpretedFeature> ?interpretedFeature .\n",
    "        ?interpretedFeature <http://interpretme.org/vocab/hasFeatureWeight> ?featureWeight .\n",
    "        ?interpretedFeature <http://www.w3.org/ns/prov#hasGeneratedBy> ?InterpretableTool .\n",
    "        ?entity <http://interpretme.org/vocab/hasEntityClassProbability> ?classProb .\n",
    "        ?classProb <http://interpretme.org/vocab/hasPredictionProbability> ?probability .\n",
    "        ?classProb <http://interpretme.org/vocab/hasClass> ?targetClass .\n",
    "        ?featureWeight <http://interpretme.org/vocab/hasFeature> ?feature .\n",
    "        ?featureWeight <http://interpretme.org/vocab/hasWeight> ?value .\n",
    "    }\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26695363",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretme_endpoint = 'http://localhost:8891/sparql'\n",
    "input_endpoint = 'http://localhost:8892/sparql'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cd9627",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configuration(interpretme_endpoint, input_endpoint)\n",
    "query_answer = federated(input_query, config)\n",
    "query_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab43a7b9",
   "metadata": {},
   "source": [
    "## Clean up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker-compose down -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e95a0e8",
   "metadata": {},
   "source": [
    "------------\n",
    "## References\n",
    "\n",
    "[1] Marco Ribeiro, Sameer Singh, and Carlos Guestrin. \"Why Should I Trust You?\": Explaining the Predictions of Any Classifier. In: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '16). ACM. 2016. DOI: [10.1145/2939672.2939778](https://dl.acm.org/doi/10.1145/2939672.2939778).\n",
    "\n",
    "[2] E. Iglesias, S. Jozashoori, D. Chaves-Fraga, D. Collarana and M.-E. Vidal. SDM-RDFizer: An RML Interpreter for the Efficient Creation of RDF Knowledge Graphs. In: CIKM ’20:Proceedings of the 29th ACM International Conference on Information & Knowledge Management, ACM, New York, NY,USA, 2020. DOI: [10.1145/3340531.3412881](https://dl.acm.org/doi/pdf/10.1145/3340531.3412881).\n",
    "\n",
    "[3] P.D. Rohde, M. Bechara, and Avellino. DeTrusty v0.12.2, June 2023. DOI: [10.5281/zenodo.8063472](https://doi.org/10.5281/zenodo.8063472)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
